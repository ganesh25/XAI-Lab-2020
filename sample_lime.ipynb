{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import and set up\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torchtext import data\n",
    "import spacy\n",
    "from torchtext import datasets\n",
    "import os\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from models.simple_rnn import RNN, CNN\n",
    "import lime\n",
    "from xai.shap import xai_shap\n",
    "\n",
    "from captum.attr import LayerIntegratedGradients, TokenReferenceBase, visualization, Lime, LayerGradientShap, LayerDeepLiftShap, LayerDeepLift\n",
    "from xai.visualize import interpret_sentence\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "device='cpu'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1b9ba97cc10>"
      ]
     },
     "metadata": {},
     "execution_count": 158
    }
   ],
   "source": [
    "#seed for reproducibility\n",
    "\n",
    "SEED = 0\n",
    "\n",
    "torch.manual_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for visualizing and interpreting\n",
    "\n",
    "def forward_with_sigmoid(model,input):\n",
    "    # print(torch.sigmoid(model(input)))\n",
    "    return torch.sigmoid(model(input.to('cuda')))\n",
    "\n",
    "# accumalate couple samples in this array for visualization purposes\n",
    "vis_data_records_ig = []\n",
    "\n",
    "def interpret_sentence(model, sentence,  TEXT, Label, min_len = 7, label = 0):\n",
    "    PAD_IND = TEXT.vocab.stoi['pad']\n",
    "    token_reference = TokenReferenceBase(reference_token_idx=PAD_IND)\n",
    "    lig = Lime(model)\n",
    "    # lig = LayerIntegratedGradients(model, model.embedding)\n",
    "    # lig = LayerGradientShap(model, model.embedding)\n",
    "    # lig = LayerDeepLift(model, model.embedding)\n",
    "\n",
    "\n",
    "    text = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    if len(text) < min_len:\n",
    "        text += ['pad'] * (min_len - len(text))\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in text]\n",
    "\n",
    "    model.zero_grad()\n",
    "\n",
    "    input_indices = torch.tensor(indexed, device=device, dtype=torch.long)\n",
    "    input_indices = input_indices.unsqueeze(0)\n",
    "\n",
    "    # input_indices dim: [sequence_length]\n",
    "    seq_length = min_len\n",
    "\n",
    "    # predict\n",
    "    pred = forward_with_sigmoid(model,input_indices)[0,0].item()\n",
    "    # print(\"Pred : \", pred)\n",
    "    pred_ind = round(pred)\n",
    "\n",
    "    # generate reference indices for each sample\n",
    "    reference_indices = token_reference.generate_reference(seq_length, device=device).unsqueeze(0)\n",
    "\n",
    "    # compute attributions and approximation delta using layer integrated gradients\n",
    "    attributions_ig, delta = lig.attribute(input_indices, reference_indices)\n",
    "\n",
    "    print('pred: ', Label.vocab.itos[pred_ind], '(', '%.2f'%pred, ')', ', delta: ', abs(delta))\n",
    "\n",
    "    add_attributions_to_visualizer(attributions_ig, text, pred, pred_ind, label, delta, vis_data_records_ig, TEXT, Label)\n",
    "    \n",
    "def add_attributions_to_visualizer(attributions, text, pred, pred_ind, label, delta, vis_data_records, TEXT, Label ):\n",
    "    attributions = attributions.sum(dim=2).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    attributions = attributions.cpu().detach().numpy()\n",
    "\n",
    "    # storing couple samples in an array for visualization purposes\n",
    "    vis_data_records.append(visualization.VisualizationDataRecord(\n",
    "                            attributions,\n",
    "                            pred,\n",
    "                            Label.vocab.itos[pred_ind],\n",
    "                            Label.vocab.itos[label],\n",
    "                            Label.vocab.itos[1],\n",
    "                            attributions.sum(),       \n",
    "                            text,\n",
    "                            delta))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data set up\n",
    "from torchtext import vocab\n",
    "import torchtext\n",
    " \n",
    "\n",
    "TEXT = torchtext.data.Field(lower=True, tokenize='spacy', batch_first=True)\n",
    "Label = torchtext.data.LabelField(dtype = torch.long)\n",
    "\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, Label)\n",
    "\n",
    "train_data, valid_data = train_data.split()\n",
    "MAX_VOCAB_SIZE = 25000\n",
    "# If you prefer to use pre-downloaded glove vectors, you can load them with the following two command line\n",
    "loaded_vectors = torchtext.vocab.Vectors('C:/Users/Abhishek Saroha/Documents/GitHub/beyond-simple-word-level-input-relevance-explanations/data/glove.6B.50d.txt')\n",
    "TEXT.build_vocab(train_data, vectors=loaded_vectors, max_size=len(loaded_vectors.stoi))\n",
    "# TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE, vectors = \"glove.6B.100d\", unk_init = torch.Tensor.normal_)\n",
    " \n",
    "TEXT.vocab.set_vectors(stoi=loaded_vectors.stoi, vectors=loaded_vectors.vectors, dim=loaded_vectors.dim)\n",
    "Label.build_vocab(train_data)\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "        (train_data, valid_data, test_data), \n",
    "        batch_size = 64,\n",
    "        device = device)\n",
    "\n",
    "PAD_IND = TEXT.vocab.stoi['pad']\n",
    "\n",
    "token_reference = TokenReferenceBase(reference_token_idx=PAD_IND)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "INPUT_DIM = 84970\n",
    "EMBEDDING_DIM = 100\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 1\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model_self = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
    "\n",
    "# trainer = pl.Trainer(max_epochs=5, gpus=1)\n",
    "# trainer.fit(model_self, train_iterator)\n",
    "model_self.load_state_dict(torch.load(\"./models/model_cnn_self_imdb.pt\"))\n",
    "model = model_self\n",
    "\n",
    "# model.load_state_dict(torch.load('models/imdb-model-cnn.pt'))\n",
    "model.eval()\n",
    "model = model.to('cuda') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-235-561a76eb2c7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#examples to interpret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0minterpret_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'It was a fantastic performance !'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTEXT\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0minterpret_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Best film ever'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTEXT\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0minterpret_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Such a great show!'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTEXT\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0minterpret_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'It was a horrible movie'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTEXT\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-233-8b95d415da24>\u001b[0m in \u001b[0;36minterpret_sentence\u001b[1;34m(model, sentence, TEXT, Label, min_len, label)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m# compute attributions and approximation delta using layer integrated gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mattributions_ig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreference_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pred: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpred_ind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'('\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'%.2f'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m')'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m', delta: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\captum\\log\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\captum\\attr\\_core\\lime.py\u001b[0m in \u001b[0;36mattribute\u001b[1;34m(self, inputs, baselines, target, additional_forward_args, feature_mask, n_perturb_samples, perturbations_per_eval, return_input_shape)\u001b[0m\n\u001b[0;32m   1077\u001b[0m                 )\n\u001b[0;32m   1078\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1079\u001b[1;33m         coefs = super().attribute.__wrapped__(\n\u001b[0m\u001b[0;32m   1080\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m             \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\captum\\attr\\_core\\lime.py\u001b[0m in \u001b[0;36mattribute\u001b[1;34m(self, inputs, target, additional_forward_args, n_perturb_samples, perturbations_per_eval, **kwargs)\u001b[0m\n\u001b[0;32m    443\u001b[0m                         \u001b[0mexpanded_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_expand_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_model_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m                     model_out = self._evaluate_batch(\n\u001b[0m\u001b[0;32m    446\u001b[0m                         \u001b[0mcurr_model_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m                         \u001b[0mexpanded_target\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\captum\\attr\\_core\\lime.py\u001b[0m in \u001b[0;36m_evaluate_batch\u001b[1;34m(self, curr_model_inputs, expanded_target, expanded_additional_args, device)\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m     ):\n\u001b[1;32m--> 494\u001b[1;33m         model_out = _run_forward(\n\u001b[0m\u001b[0;32m    495\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m             \u001b[0m_reduce_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_model_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\captum\\_utils\\common.py\u001b[0m in \u001b[0;36m_run_forward\u001b[1;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[0madditional_forward_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_format_additional_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madditional_forward_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 373\u001b[1;33m     output = forward_func(\n\u001b[0m\u001b[0;32m    374\u001b[0m         \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0madditional_forward_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0madditional_forward_args\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Abhishek Saroha\\Documents\\GitHub\\beyond-simple-word-level-input-relevance-explanations\\models\\simple_rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m#text = [batch size, sent len]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[1;31m# text=text.to('cuda')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[0membedded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         return F.embedding(\n\u001b[0m\u001b[0;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   1812\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1813\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1814\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1815\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1816\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "#examples to interpret\n",
    "interpret_sentence(model, 'It was a fantastic performance !', TEXT=TEXT, Label=Label, label=1)\n",
    "interpret_sentence(model, 'Best film ever', TEXT=TEXT, Label=Label, label=1)\n",
    "interpret_sentence(model, 'Such a great show!', TEXT=TEXT, Label=Label, label=1)\n",
    "interpret_sentence(model, 'It was a horrible movie', TEXT=TEXT, Label=Label, label=0)\n",
    "interpret_sentence(model, 'I\\'ve never watched something as bad', TEXT=TEXT, Label=Label, label=0)\n",
    "interpret_sentence(model, 'It is a disgusting movie!', TEXT=TEXT, Label=Label, label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Visualize attributions based on Integrated Gradients\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>neg (0.38)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-1.94</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(0, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 75%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fantastic                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> performance                    </font></mark><mark style=\"background-color: hsl(0, 75%, 75%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> !                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.88)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-0.67</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 66%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Best                    </font></mark><mark style=\"background-color: hsl(120, 75%, 78%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> film                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ever                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>neg (0.16)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-1.88</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Such                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> great                    </font></mark><mark style=\"background-color: hsl(0, 75%, 74%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> show                    </font></mark><mark style=\"background-color: hsl(0, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> !                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.83)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-0.56</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(0, 75%, 67%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> horrible                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movie                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>neg (0.03)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-1.85</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> I                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 've                    </font></mark><mark style=\"background-color: hsl(0, 75%, 65%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> never                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> watched                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> something                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>neg (0.33)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-2.24</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(0, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> disgusting                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movie                    </font></mark><mark style=\"background-color: hsl(0, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> !                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr></table>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "print('Visualize attributions based on Integrated Gradients')\n",
    "visualization.visualize_text(vis_data_records_ig)\n",
    "vis_data_records_ig = [] #to clear for future references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./models/imdb-model-cnn.pt')\n",
    "model.eval()\n",
    "model = model.to('cuda') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pred:  pos ( 0.56 ) , delta:  tensor([0.5090], device='cuda:0')\npred:  pos ( 0.50 ) , delta:  tensor([0.2917], device='cuda:0')\npred:  pos ( 0.56 ) , delta:  tensor([0.9208], device='cuda:0')\npred:  neg ( 0.50 ) , delta:  tensor([0.0890], device='cuda:0')\npred:  pos ( 0.97 ) , delta:  tensor([11.7807], device='cuda:0')\npred:  neg ( 0.47 ) , delta:  tensor([0.3219], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#examples to interpret\n",
    "interpret_sentence(model, 'It was a fantastic performance !', TEXT=TEXT, Label=Label, label=1)\n",
    "interpret_sentence(model, 'Best film ever', TEXT=TEXT, Label=Label, label=1)\n",
    "interpret_sentence(model, 'Such a great show!', TEXT=TEXT, Label=Label, label=1)\n",
    "interpret_sentence(model, 'It was a horrible movie', TEXT=TEXT, Label=Label, label=0)\n",
    "interpret_sentence(model, 'I\\'ve never watched something as bad', TEXT=TEXT, Label=Label, label=0)\n",
    "interpret_sentence(model, 'It is a disgusting movie!', TEXT=TEXT, Label=Label, label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Visualize attributions based on Integrated Gradients\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.56)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>1.28</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 73%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fantastic                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> performance                    </font></mark><mark style=\"background-color: hsl(120, 75%, 64%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> !                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.50)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-0.21</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Best                    </font></mark><mark style=\"background-color: hsl(120, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> film                    </font></mark><mark style=\"background-color: hsl(0, 75%, 65%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ever                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.56)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>1.75</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Such                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> great                    </font></mark><mark style=\"background-color: hsl(120, 75%, 73%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> show                    </font></mark><mark style=\"background-color: hsl(120, 75%, 62%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> !                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>neg (0.50)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>0.01</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 73%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(0, 75%, 77%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> horrible                    </font></mark><mark style=\"background-color: hsl(120, 75%, 77%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movie                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.97)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>1.89</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> I                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 've                    </font></mark><mark style=\"background-color: hsl(120, 75%, 57%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> never                    </font></mark><mark style=\"background-color: hsl(120, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> watched                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> something                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>neg (0.47)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-0.21</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(120, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 66%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> disgusting                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movie                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> !                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr></table>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "print('Visualize attributions based on Integrated Gradients')\n",
    "visualization.visualize_text(vis_data_records_ig)\n",
    "vis_data_records_ig = [] #to clear for future references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(20002, 100)\n",
       "  (rnn): LSTM(100, 256)\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (output): Softmax(dim=None)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "\n",
    "##running with our basic 50% rnn\n",
    "#call model\n",
    "model_rnn = RNN()\n",
    "\n",
    "#get data\n",
    "text, labels, train_data, test_data, valid_data, train_iterator, valid_iterator, test_iterator = model_rnn.preprocess_data(device, BATCH_SIZE=64)\n",
    "\n",
    "# init model\n",
    "INPUT_DIM = len(text.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "\n",
    "model_rnn.create_model(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "\n",
    "model_rnn.load_state_dict(torch.load(\"./models/model_imdb.pt\"))\n",
    "\n",
    "model_rnn.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pred:  pos ( 0.73 ) , delta:  0\n",
      "pred:  pos ( 0.73 ) , delta:  0\n",
      "pred:  pos ( 0.73 ) , delta:  0\n",
      "pred:  pos ( 0.73 ) , delta:  0\n",
      "pred:  pos ( 0.73 ) , delta:  0\n",
      "pred:  pos ( 0.73 ) , delta:  0\n"
     ]
    }
   ],
   "source": [
    "interpret_sentence(model_rnn, 'It was a fantastic performance !', TEXT=text, Label=labels, label=1)\n",
    "interpret_sentence(model_rnn, 'Best film ever', TEXT=text, Label=labels, label=1)\n",
    "interpret_sentence(model_rnn, 'Such a great show!', TEXT=text, Label=labels, label=1)\n",
    "interpret_sentence(model_rnn, 'It was a horrible movie', TEXT=text, Label=labels, label=0)\n",
    "interpret_sentence(model_rnn, 'I\\'ve never watched something as bad', TEXT=text, Label=labels, label=0)\n",
    "interpret_sentence(model_rnn, 'It is a disgusting movie!', TEXT=text, Label=labels, label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Visualize attributions based on Integrated Gradients\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.73)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>nan</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fantastic                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> performance                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> !                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.73)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>nan</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Best                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> film                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ever                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.73)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>nan</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Such                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> great                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> show                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> !                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.73)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>nan</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> horrible                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movie                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.73)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>nan</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> I                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 've                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> never                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> watched                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> something                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.73)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>nan</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> disgusting                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movie                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> !                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr></table>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "print('Visualize attributions based on Integrated Gradients')\n",
    "visualization.visualize_text(vis_data_records_ig)\n",
    "vis_data_records_ig = [] #to clear for future references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}